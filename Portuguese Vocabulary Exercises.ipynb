{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portuguese Vocabulary Exercises\n",
    "### Project by Thomas Lindstrom-Vautrin\n",
    "Learning languages is a hobby of mine. One of the languages I have taken an interest in is Portuguese. As I have been learning, I have tried to find ways to make that learning more effective. My goal with this project is simply to have a place to train on Portuguese vocabulary as I continue to learn the language. The main feature I will implement is a means of extracting relevant vocabulary from Portuguese text copied and pasted from any online source. In particular, when watching a Portuguese language show on Netflix, I want to be able to copy and paste the Portuguese subtitles into this program and extract the most relevant vocabulary terms so that I can anticipate them before watching an episode. But this extends also to news articles I may read in Portuguese, or chapters I read in e-books... Any Portuguese text should work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "Here we install and import all the necessary packages. Originally I used the Google Translate package instead of performing my own machine translation, since the main thrust of this project is identifying relevant vocabulary and not translating that vocabulary, but this package became unreliable. Instead I decide not to translate words at all and simply provide sentences which may contain them, based on data we already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy.stats import arcsine\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preparing for this project, I referenced the following notebook: https://medium.com/dair-ai/neural-machine-translation-with-attention-using-pytorch-a66523f1669f\n",
    "\n",
    "Some code has been adapted from that notebook, and we use data from the same original source: http://www.manythings.org/anki/\n",
    "\n",
    "In the following code we import and clean the Portuguese phrases which we use as a basis for our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['eng', 'pt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lines = open('data/por.txt', encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "original_phrases = [[p for p in l.split('\\t')] for l in lines]\n",
    "\n",
    "data = pd.DataFrame(original_phrases, columns=[\"eng\", \"pt\", \"other\"])\n",
    "del(data[\"other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vai.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vá.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>ir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Oi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157970</th>\n",
       "      <td>I recommend contributing sentences in your own...</td>\n",
       "      <td>Eu recomendo contribuir com frases em seu próp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157971</th>\n",
       "      <td>I recommend contributing sentences in your own...</td>\n",
       "      <td>Recomendo que você contribua com frases em seu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157972</th>\n",
       "      <td>No matter how much you try to convince people ...</td>\n",
       "      <td>Não importa o quanto você tenta convencer os o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157973</th>\n",
       "      <td>Some movies make such an impact that one never...</td>\n",
       "      <td>Alguns filmes são tão marcantes que jamais nos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157974</th>\n",
       "      <td>A child who is a native speaker usually knows ...</td>\n",
       "      <td>Uma criança que é falante nativa geralmente sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                     Go.   \n",
       "2                                                     Go.   \n",
       "3                                                     Hi.   \n",
       "4                                                    Run!   \n",
       "...                                                   ...   \n",
       "157970  I recommend contributing sentences in your own...   \n",
       "157971  I recommend contributing sentences in your own...   \n",
       "157972  No matter how much you try to convince people ...   \n",
       "157973  Some movies make such an impact that one never...   \n",
       "157974  A child who is a native speaker usually knows ...   \n",
       "\n",
       "                                                       pt  \n",
       "0                                                    Vai.  \n",
       "1                                                     Vá.  \n",
       "2                                                     ir.  \n",
       "3                                                     Oi.  \n",
       "4                                                  Corre!  \n",
       "...                                                   ...  \n",
       "157970  Eu recomendo contribuir com frases em seu próp...  \n",
       "157971  Recomendo que você contribua com frases em seu...  \n",
       "157972  Não importa o quanto você tenta convencer os o...  \n",
       "157973  Alguns filmes são tão marcantes que jamais nos...  \n",
       "157974  Uma criança que é falante nativa geralmente sa...  \n",
       "\n",
       "[157975 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a sentence into a string of space-separated words without punctuation.\n",
    "def words_only(w):\n",
    "    # These characters have been identified as the Portuguese-language word-forming characters in our dataset.\n",
    "    w = re.sub(r\"[^oeasrmiuntdclpvqThãfEgêbáézVOjNAçMóPxQíySCDàIFBÉúHJôGUõLâkRwKÀYÁWXÍZÓÂ]+\", \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    \n",
    "    return w\n",
    "\n",
    "# Transform a sentence into a string of space-separated words with space-separated \"final punctuation\".\n",
    "def final_punctuation(w):\n",
    "    # Add a space before and after \"final punctuation\".\n",
    "    # \"Final punctuation\" is defined as punctuation which either ends a sentence or begins a quotation.\n",
    "    # In either of these cases the following character is likely to be capitalized even if the word is not\n",
    "    # a named entity, which is relevant for rudimentary identification of named entities.\n",
    "    w = re.sub(r'([?.!\\'\"])', r\" \\1 \", w)\n",
    "    w = re.sub(r'[ ]+', \" \", w)\n",
    "    \n",
    "    w = re.sub(r'[^oeasrmiuntdclpvqThãfEgêbáézVOjNAçMóPxQíySCDàIFBÉúHJôGUõLâkRwKÀYÁWXÍZÓÂ?.!\\'\"]+', \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    \n",
    "    return w\n",
    "\n",
    "# Extracted from \"NMT in PyTorch\" tutorial.\n",
    "# https://medium.com/dair-ai/neural-machine-translation-with-attention-using-pytorch-a66523f1669f\n",
    "def preprocess_sentence(w, context=1):\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r'([?.!,])', r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except the existing acceptable characters and \".\", \"?\", \"!\", \",\"\n",
    "    w = re.sub(r\"[^oeasrmiuntdclpvqThãfEgêbáézVOjNAçMóPxQíySCDàIFBÉúHJôGUõLâkRwKÀYÁWXÍZÓÂ?.!,]+\", \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    for i in range(context):\n",
    "        w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rudimentary Named Entity Recognition\n",
    "It will be useful to identify words which are named entities and do not constitute typical words in the vocabulary. We will use the simple heuristic that a word which is capitalized in the middle of a sentence is most likely a named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rudimentary approach to named entity recognition:\n",
    "# Identify non-lowercase words in parts of the phrase which are not the beginning of the sentence\n",
    "# or after \"final punctuation\".\n",
    "\n",
    "fin_punct = ['?', '.', '!', \"'\", '\"']\n",
    "\n",
    "# Identify all words in the corpus, including different capitalizations.\n",
    "all_words = set()\n",
    "for phrase in data[\"pt\"]:\n",
    "    all_words.update(words_only(phrase).split(' '))\n",
    "\n",
    "# Perform a rudimentary form of named entity recognition.\n",
    "# Identify capitalized words which are not at the beginning of a sentence.\n",
    "def rudimentary_NER(phrases=data[\"pt\"], vocab=all_words):\n",
    "    named_entities = set()\n",
    "\n",
    "    for phrase in phrases:\n",
    "        phrase_words = words_only(phrase).split(' ')\n",
    "        phrase = final_punctuation(phrase).split(' ')\n",
    "        for i in range(len(phrase)):\n",
    "            # If the word is indeed a word and not punctuation and if the word is not all lowercase...\n",
    "            if phrase[i] not in fin_punct and phrase[i] != phrase[i].lower():\n",
    "                # If the word is not the first word and does not follow \"final punctuation\"...\n",
    "                if phrase[i] != phrase_words[0] and phrase[i-1] not in fin_punct:\n",
    "                        named_entities.add(phrase[i]) # This is a named entity.\n",
    "                # If it does have an excuse to be capitalized...\n",
    "                else:\n",
    "                    # Check if it has an all lowercase form in the vocabulary...\n",
    "                    if phrase[i].lower() not in all_words:\n",
    "                        named_entities.add(phrase[i])\n",
    "    \n",
    "    return named_entities\n",
    "\n",
    "named_entities = rudimentary_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the two most obvious incorrectly identified named entities\n",
    "named_entities.remove('A') # feminine equivalent of \"the\"\n",
    "named_entities.remove('O') # masculine equivalent of \"the\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to create a list of vocabulary extracted from the phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter()\n",
    "\n",
    "# Get the counts for each word, treating named entities seperately.\n",
    "# We do not remove named entities so that they can still be used in sentence production.\n",
    "for phrase in data[\"pt\"]:\n",
    "    for word in words_only(phrase).split(' '):\n",
    "        if word in named_entities:\n",
    "            count[word] += 1\n",
    "        else:\n",
    "            count[word.lower()] += 1\n",
    "\n",
    "# Define the vocabulary as the words ordered by count. Keep track of these counts also.\n",
    "vocab = [w for w, c in sorted(count.items(), key=lambda x: x[1], reverse=True)]\n",
    "count = [c for w, c in sorted(count.items(), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "# Get the frequencies from the counts.       \n",
    "total_count = sum(count)\n",
    "freq = [c/total_count for c in count]\n",
    "\n",
    "# Identify the indices of the named entities. We don't need to know which is which.\n",
    "named_entity_indices = set()\n",
    "for index, word in enumerate(vocab):\n",
    "    if word in named_entities:\n",
    "        named_entity_indices.add(index)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we match each word to the phrases containing it. The following code is commented out because it only needs to be performed once. We then proceed to save the data, and then reload it since it takes some time to generate this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_words_to_phrases():\n",
    "    # For each word, get all the phrases which contain it.\n",
    "    phrase_words = [[word if word in named_entities else word.lower() for word in words_only(phrase).split(' ')] for phrase in data[\"pt\"]]\n",
    "    words_to_phrases = {}\n",
    "    for i in range(len(phrase_words)):\n",
    "        for word in phrase_words[i]:\n",
    "            if word in words_to_phrases.keys():\n",
    "                words_to_phrases[word].append(data[\"pt\"][i])\n",
    "            else:\n",
    "                words_to_phrases[word] = [data[\"pt\"][i]]\n",
    "\n",
    "    pickle_out = open(\"words_to_phrases.pickle\", \"wb\")\n",
    "    pickle.dump(words_to_phrases, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt2en_phrases = {}\n",
    "for i in range(len(data[\"pt\"])):\n",
    "    pt2en_phrases[data[\"pt\"][i]] = data[\"eng\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vai.',\n",
       " 'Vai-te embora!',\n",
       " 'Vai para dentro.',\n",
       " 'Como vai o Tom?',\n",
       " 'Tom vai.',\n",
       " 'A gente vai tentar.',\n",
       " 'Quem vai?',\n",
       " 'Como vai o Tom?',\n",
       " 'Isso vai funcionar.',\n",
       " 'Vai funcionar.',\n",
       " 'Isso vai servir.',\n",
       " 'Tom vai chorar.',\n",
       " 'Tom vai morrer.',\n",
       " 'Vai encontrar Tom.',\n",
       " 'Vai achar o Tom.',\n",
       " 'Vai para casa agora.',\n",
       " 'Vai por ali.',\n",
       " 'Como vai?',\n",
       " 'Como vai você?',\n",
       " 'Vai ficar tudo bem.',\n",
       " 'Tom vai vir.',\n",
       " 'Tom vai saber.',\n",
       " 'Tom vai perder.',\n",
       " 'Tom vai ficar.',\n",
       " 'Tom vai falar.',\n",
       " 'Tom vai esperar.',\n",
       " 'A gente vai compartilhar.',\n",
       " 'Quem vai cozinhar?',\n",
       " 'Ele vai morrer?',\n",
       " 'Você vai?',\n",
       " 'Você vai perder.',\n",
       " 'Vai à escola.',\n",
       " 'Ele vai caminhar.',\n",
       " 'Como vai a escola?',\n",
       " 'Vai queimar.',\n",
       " 'Isso vai queimar.',\n",
       " 'Vai funcionar.',\n",
       " 'Isso vai acontecer.',\n",
       " 'Isso vai ajudar.',\n",
       " 'Isso vai ajudar.',\n",
       " 'Isso vai funcionar.',\n",
       " 'Tom vai chorar.',\n",
       " 'Tom vai morrer.',\n",
       " 'Tom vai pagar.',\n",
       " 'Tom vai tentar.',\n",
       " 'Tom vai vencer.',\n",
       " 'Tom vai falar.',\n",
       " 'Quem vai pagar?',\n",
       " 'Quem vai ganhar?',\n",
       " 'Quem vai dirigir?',\n",
       " 'Quem vai começar?',\n",
       " 'Quem vai pagar?',\n",
       " 'O Tom vai morrer?',\n",
       " 'Ele vai viver?',\n",
       " 'Você não vai?',\n",
       " 'Você vai morrer.',\n",
       " 'Você vai fazer.',\n",
       " 'Você vai fazer isso.',\n",
       " 'Ele não vai saber.',\n",
       " 'E você, como vai?',\n",
       " 'Como vai?',\n",
       " 'Não vai doer.',\n",
       " 'Não vai abrir.',\n",
       " 'Isso não vai funcionar.',\n",
       " 'Vai ficar bem.',\n",
       " 'Tom vai ligar.',\n",
       " 'Tom vai vir.',\n",
       " 'Tom vai ajudar.',\n",
       " 'Tom vai perder.',\n",
       " 'Tom vai obedecer.',\n",
       " 'Tom vai desistir.',\n",
       " 'Tom vai cantar.',\n",
       " 'Tom vai ficar.',\n",
       " 'Tom vai falar.',\n",
       " 'Tom vai esperar.',\n",
       " 'Tom vai trabalhar.',\n",
       " 'O Tom não vai comer.',\n",
       " 'Tom não vai comer.',\n",
       " 'Tom não vai ganhar.',\n",
       " 'Tom não vai vencer.',\n",
       " 'Tom vai mudar.',\n",
       " 'A gente vai sobreviver.',\n",
       " 'Você vai nadar?',\n",
       " 'Você vai ajudar.',\n",
       " 'Você vai perder.',\n",
       " 'Você vai obedecer.',\n",
       " 'Você vai esperar.',\n",
       " 'Você não vai morrer.',\n",
       " 'Você vai longe.',\n",
       " 'Vai lá, Tom!',\n",
       " 'Vai passear.',\n",
       " 'Como vai?',\n",
       " 'Eu disse: vai embora.',\n",
       " 'Eu disse: vai para casa.',\n",
       " 'Vai ficar pronto.',\n",
       " 'Isso vai funcionar.',\n",
       " 'Vai funcionar agora.',\n",
       " 'Ninguém vai saber.',\n",
       " 'Ela vai voltar.',\n",
       " 'Vai custar 30 dólares.',\n",
       " 'Isso vai custar 30 dólares.',\n",
       " 'Isso vai ajudar.',\n",
       " 'Isso vai funcionar.',\n",
       " 'Tom vai concordar.',\n",
       " 'Tom vai dançar.',\n",
       " 'Tom vai fazer isto.',\n",
       " 'Tom vai dirigir.',\n",
       " 'Tom vai falar.',\n",
       " 'Tom vai começar.',\n",
       " 'Tom não vai vir.',\n",
       " 'Tom não vai ajudar.',\n",
       " 'Tom não vai se importar.',\n",
       " 'Tom não vai cantar.',\n",
       " 'Tom não vai parar.',\n",
       " 'Tom vai se recuperar.',\n",
       " 'Tom vai sobreviver.',\n",
       " 'O que vai acontecer?',\n",
       " 'O que você vai fazer?',\n",
       " 'Você vai fazer o quê?',\n",
       " 'Você vai aprender.',\n",
       " 'Você vai ganhar um.',\n",
       " 'Você vai receber um.',\n",
       " 'Você vai se molhar.',\n",
       " 'Você vai gostar.',\n",
       " 'Você vai adorar.',\n",
       " 'Você vai sentir saudades de mim.',\n",
       " 'Você vai ficar com saudades de mim',\n",
       " 'Você vai precisar disso.',\n",
       " 'Ninguém vai tentar.',\n",
       " 'Ele vai sobreviver.',\n",
       " 'Oi! Como vai você?',\n",
       " 'Olá! Como vai você?',\n",
       " 'Oi! Como vai você?',\n",
       " 'Como vai você?',\n",
       " 'Como vai?',\n",
       " 'Como vai você?',\n",
       " 'Como vai o Tom?',\n",
       " 'Isso não vai importar.',\n",
       " 'Não vai importar.',\n",
       " 'Vai melhorar.',\n",
       " 'Isso vai melhorar.',\n",
       " 'Vai ficar nublado.',\n",
       " 'Vai piorar.',\n",
       " 'Vai levar tempo.',\n",
       " 'Isso não vai ajudar.',\n",
       " 'Isso não vai funcionar!',\n",
       " 'Isso não vai funcionar.',\n",
       " 'Vai ficar bem.',\n",
       " 'Isso vai ser difícil.',\n",
       " 'Vai ser legal.',\n",
       " 'Isso não vai queimar.',\n",
       " 'Isso não vai ajudar.',\n",
       " 'Isso não vai funcionar.',\n",
       " 'Tom não vai.',\n",
       " 'O Tom vai aceitar.',\n",
       " 'Tom vai decidir.',\n",
       " 'Tom vai escutar.',\n",
       " 'Tom vai nos ver.',\n",
       " 'Tom vai sofrer.',\n",
       " 'Tom não vai fazer isso.',\n",
       " 'Tom vai descobrir.',\n",
       " 'Tom vai se lembrar.',\n",
       " 'O que o Tom vai falar?',\n",
       " 'O que o Tom vai dizer?',\n",
       " 'O que é que o Tom vai dizer?',\n",
       " 'Quanto vai custar?',\n",
       " 'Quanto vai ser?',\n",
       " 'Quanto isso vai custar?',\n",
       " 'O Tom vai comer isso?',\n",
       " 'Ele vai se recuperar?',\n",
       " 'Você vai se lamentar.',\n",
       " 'Você vai se machucar.',\n",
       " 'Você vai se perder.',\n",
       " 'Você vai gostar do Tom.',\n",
       " 'Você vai conhecer o Tom.',\n",
       " 'Você vai sentir saudades do Tom.',\n",
       " 'Você vai precisar de um.',\n",
       " 'Você vai me agradecer.',\n",
       " 'Vai se divertir um pouco.',\n",
       " 'Vai brincar com Tom.',\n",
       " 'Ele não vai me pegar.',\n",
       " 'Ele vai entender.',\n",
       " 'Ele vai sair num instante.',\n",
       " 'Como vai o Tom?',\n",
       " 'Como vai você?',\n",
       " 'Como você vai?',\n",
       " 'Como vai a família?',\n",
       " 'Isso não vai ser difícil.',\n",
       " 'Isso não vai demorar.',\n",
       " 'Nunca vai funcionar.',\n",
       " 'Vai nevar hoje.',\n",
       " 'Vai levar horas.',\n",
       " 'Ninguém vai falar.',\n",
       " 'Ninguém vai se importar.',\n",
       " 'Ninguém vai ligar.',\n",
       " 'Ninguém vai saber.',\n",
       " 'Tom vai estar aqui.',\n",
       " 'Tom vai se atrasar.',\n",
       " 'Tom vai fazer isto.',\n",
       " 'Tom vai explicar.',\n",
       " 'Tom vai encontrá-lo.',\n",
       " 'Tom vai me encontrar.',\n",
       " 'Tom vai nos encontrar.',\n",
       " 'Tom vai pegar um.',\n",
       " 'Tom vai me ajudar.',\n",
       " 'Tom vai nos ajudar.',\n",
       " 'Tom vai melhorar.',\n",
       " 'Tom vai me matar.',\n",
       " 'Tom vai gostar de mim.',\n",
       " 'Tom vai conseguir.',\n",
       " 'Tom vai responder.',\n",
       " 'Tom vai nos salvar.',\n",
       " 'Tom vai aparecer.',\n",
       " 'Tom vai sobreviver.',\n",
       " 'Tom vai nos contar.',\n",
       " 'Tom vai nos dizer.',\n",
       " 'Tom não vai perceber.',\n",
       " 'Tom não vai se aposentar.',\n",
       " 'Tom não vai morrer de fome.',\n",
       " 'O que vai acontecer?',\n",
       " 'Que vai fazer você?',\n",
       " 'Quando você vai partir?',\n",
       " 'Quando você vai embora?',\n",
       " 'Quando isso vai acabar?',\n",
       " 'Quando você vai?',\n",
       " 'Quem vai me ajudar?',\n",
       " 'O Tom vai sobreviver?',\n",
       " 'Isso vai mudar?',\n",
       " 'Você vai fazer isso?',\n",
       " 'Você vai me encontrar?',\n",
       " 'Você também vai?',\n",
       " 'Você vai arriscar?',\n",
       " 'Você vai levar isso?',\n",
       " 'Você vai se conformar.',\n",
       " 'Você vai sobreviver.',\n",
       " 'Você vai ser demitido.',\n",
       " 'Você vai ser demitida.',\n",
       " 'Você vai ficar cansado.',\n",
       " 'Você vai ficar cansada.',\n",
       " 'Você vai se cansar.',\n",
       " 'Você vai gostar disso.',\n",
       " 'Você vai precisar de mais.',\n",
       " 'Você vai precisar disso.',\n",
       " 'Você vai precisar disso.',\n",
       " 'Você nunca vai vencer.',\n",
       " 'Você não vai.',\n",
       " 'Você vai sair?',\n",
       " 'Ele vai voltar.',\n",
       " 'Como vai?',\n",
       " 'Como vai você?',\n",
       " 'Como vai?',\n",
       " 'Como vai você?',\n",
       " 'Como vai você?',\n",
       " 'Como vai a família?',\n",
       " 'Como vai a sua família?',\n",
       " 'Como vai a sua mãe?',\n",
       " 'O Tom vai também?',\n",
       " 'Vai nos dois sentidos.',\n",
       " 'Isto não vai dar certo.',\n",
       " 'Não vai dar certo.',\n",
       " 'Vai valer a pena.',\n",
       " 'Nada vai ajudar.',\n",
       " 'Nada vai acontecer.',\n",
       " 'Isso não vai acontecer.',\n",
       " 'O Tom vai ser demitido.',\n",
       " 'Tom vai ficar feliz.',\n",
       " 'Tom vai estar lá.',\n",
       " 'Tom vai ficar cansado.',\n",
       " 'Tom vai te chamar.',\n",
       " 'Tom vai reclamar.',\n",
       " 'Tom vai continuar.',\n",
       " 'Tom vai comer em breve.',\n",
       " 'Tom vai te achar.',\n",
       " 'Tom vai te encontrar.',\n",
       " 'Tom vai consertar isso.',\n",
       " 'Tom vai se levantar.',\n",
       " 'Tom vai primeiro.',\n",
       " 'O Tom vai ouvir você.',\n",
       " 'O Tom vai te ajudar.',\n",
       " 'Tom vai te matar.',\n",
       " 'Tom não vai te obedecer.',\n",
       " 'Tom vai te contar.',\n",
       " 'O Tom vai me agradecer.',\n",
       " 'Tom não vai escapar.',\n",
       " 'O Tom não vai querer isso.',\n",
       " 'Tom vai entender.',\n",
       " 'O que você vai beber?',\n",
       " 'Você vai ligar para o Tom?',\n",
       " 'Você vai chamar o Tom?',\n",
       " 'Você não vai fazer isso?',\n",
       " 'Você não vai se juntar a nós?',\n",
       " 'Você não vai me bater.',\n",
       " 'Você vai ficar comigo.',\n",
       " 'Você vai encontrar um emprego.',\n",
       " 'Você vai melhorar.',\n",
       " 'Você vai ser pego.',\n",
       " 'Você vai ter que ir.',\n",
       " 'Você vai ter de ir.',\n",
       " 'Você vai precisar de dinheiro.',\n",
       " 'Você também vai?',\n",
       " 'Você vai ir também?',\n",
       " 'O que vem fácil, vai fácil.',\n",
       " 'Vai embora daqui.',\n",
       " 'Ele vai à escola caminhando.',\n",
       " 'Ele não vai gostar disto.',\n",
       " 'Oi! Como vai você?',\n",
       " 'Como vai a sua família?',\n",
       " 'Como vai sua família?',\n",
       " 'Como vai a tua família?',\n",
       " 'Como vai a sua mãe?',\n",
       " 'Eu acho que você vai ganhar.',\n",
       " 'Eu acho que você vai vencer.',\n",
       " 'Parece que vai chover.',\n",
       " 'Parece que vai chover.',\n",
       " 'Não vai ser o suficiente.',\n",
       " 'Não vai durar muito.',\n",
       " 'Vai dar tudo certo.',\n",
       " 'Vai ser difícil.',\n",
       " 'Vai ser hilário.',\n",
       " 'Isso vai acontecer novamente.',\n",
       " 'Vai chover.',\n",
       " 'Ninguém vai perceber.',\n",
       " 'Ninguém vai notar.',\n",
       " 'Ela vai à escola.',\n",
       " 'Isso vai ser engraçado.',\n",
       " 'Isso não vai me ajudar.',\n",
       " 'Lá vai nosso ônibus.',\n",
       " 'Tom vai ficar bem.',\n",
       " 'O Tom vai se desculpar.',\n",
       " 'Tom vai dormir.',\n",
       " 'Tom nunca vai parar.',\n",
       " 'Tom vai voltar.',\n",
       " 'Tom vai cooperar.',\n",
       " 'Tom vai encontrar a Mary.',\n",
       " 'Tom vai encontrá-los.',\n",
       " 'Tom vai encontrá-las.',\n",
       " 'Tom vai ajudar a Mary.',\n",
       " 'Tom vai matar a Mary.',\n",
       " 'Tom vai precisar de ajuda.',\n",
       " 'Tom vai trabalhar duro.',\n",
       " 'O Tom não vai ser demitido.',\n",
       " 'Tom não vai descobrir.',\n",
       " 'O que você vai vestir?',\n",
       " 'O que vai acontecer agora?',\n",
       " 'O que você vai fazer agora?',\n",
       " 'Vai doer muito?',\n",
       " 'Você vai ajudá-los?',\n",
       " 'Você vai ajudá-las?',\n",
       " 'Você vai ficar, Tom?',\n",
       " 'Você não vai ser demitido.',\n",
       " 'Você não vai se arrepender.',\n",
       " 'Você vai se recuperar.',\n",
       " 'Você vai morrer na cadeia.',\n",
       " 'Você vai se sentir melhor.',\n",
       " 'Você vai se encaixar bem.',\n",
       " 'Você não vai conseguir nada.',\n",
       " 'Você não vai ganhar nada.',\n",
       " 'Você não vai receber nada.',\n",
       " 'Você não vai obter nada.',\n",
       " 'Você vai ter de pagar.',\n",
       " 'Você vai se arrepender disso!',\n",
       " 'Você vai se arrepender!',\n",
       " 'Vai escovar os dentes.',\n",
       " 'Como vai o seu irmão?',\n",
       " 'Quanto vai custar?',\n",
       " 'Quanto vai ser?',\n",
       " 'Como é que o Tom vai entrar?',\n",
       " 'Como vai, Tom?',\n",
       " 'Eu fico imaginando quem vai ganhar.',\n",
       " 'O Tom vai morrer?',\n",
       " 'Vai doer?',\n",
       " 'Vai chover?',\n",
       " 'Vai chover.',\n",
       " 'Vai nevar.',\n",
       " 'Vai ser um bom dia.',\n",
       " 'Provavelmente vai chover.',\n",
       " 'Vai chover, com certeza.',\n",
       " 'Vai chover amanhã.',\n",
       " 'Amanhã vai nevar.',\n",
       " 'Isso vai quebrar.',\n",
       " 'Meu pai vai me matar.',\n",
       " 'O meu pai vai me matar.',\n",
       " 'Ninguém vai sobreviver.',\n",
       " 'Ela não vai gostar disto.',\n",
       " 'Ela vai me matar.',\n",
       " 'Isso não vai te ajudar.',\n",
       " 'Tom vai a pé para a escola.',\n",
       " 'Tom vai ficar furioso.',\n",
       " 'Tom nunca vai saber.',\n",
       " 'Tom nunca vai parar.',\n",
       " 'Tom vai entender.',\n",
       " 'O Tom não vai pedir desculpas.',\n",
       " 'Tom não vai ligar para a Mary.',\n",
       " 'Tom não vai vir para casa.',\n",
       " 'Tom não vai ajudar a Mary.',\n",
       " 'Tom não vai beijar Mary.',\n",
       " 'Tom não vai te deixar.',\n",
       " 'Tom, como vai você?',\n",
       " 'O que você vai comer?',\n",
       " 'O que você vai querer?',\n",
       " 'Quando você vai se mudar?',\n",
       " 'Quando você vai começar?',\n",
       " 'Quando você vai partir?',\n",
       " 'Aonde você vai?',\n",
       " 'Para onde vai isto?',\n",
       " 'Onde você vai ficar?',\n",
       " 'Qual time vai ganhar?',\n",
       " 'Qual time vai vencer?',\n",
       " 'Quem vai pagar a conta?',\n",
       " 'Quem vai pagar o aluguel?',\n",
       " 'Quem vai saber?',\n",
       " 'Quem vai te substituir?',\n",
       " 'Isto vai me afetar?',\n",
       " 'Você vai jantar?',\n",
       " 'Você vai almoçar?',\n",
       " 'Você vai vir conosco?',\n",
       " 'Você vai precisar de uma chave.',\n",
       " 'Você não vai morrer hoje.',\n",
       " 'Você vai pegar um resfriado.',\n",
       " 'Você não vai sentir nada.',\n",
       " 'Você vai ou não vai?',\n",
       " 'Você vai ou não vai?',\n",
       " 'Você vai ou vai ficar?',\n",
       " 'Você vai ou vai ficar?',\n",
       " 'Você vai comer?',\n",
       " 'Você não vai entrar?',\n",
       " 'Vai em frente, eu te desafio!',\n",
       " 'Oi, como vai você?',\n",
       " 'Como vai a sua filha?',\n",
       " 'Como vai o trabalho?',\n",
       " 'Como vai o seu menino?',\n",
       " 'Eu sei como isso vai.',\n",
       " 'Sei como isso vai.',\n",
       " 'Eu queria saber quem vai voltar.',\n",
       " 'Eu me pergunto quem vai voltar.',\n",
       " 'Vai mais alguém?',\n",
       " 'Alguém mais vai?',\n",
       " 'Isso vai me custar o meu trabalho.',\n",
       " 'Vai acontecer hoje à noite.',\n",
       " 'A justiça vai prevalecer.',\n",
       " 'Ninguém vai se machucar.',\n",
       " 'Ninguém vai te ajudar.',\n",
       " 'Essa porta não vai abrir.',\n",
       " 'Este carro não vai ligar.',\n",
       " 'Esta porta não vai trancar.',\n",
       " 'Vai custar €30.',\n",
       " 'Vai ter que servir.',\n",
       " 'Isto vai ter que servir.',\n",
       " 'Isto vai ter de servir.',\n",
       " 'Esta madeira não vai queimar.',\n",
       " 'Tom vai ficar.',\n",
       " 'O Tom não vai fazer isso.',\n",
       " 'Tom vai ficar emocionado.',\n",
       " 'Tom vai te perdoar.',\n",
       " 'O Tom jamais vai concordar.',\n",
       " 'O Tom vai me esperar.',\n",
       " 'O Tom vai esperar por nós.',\n",
       " 'O Tom vai esperar pela gente.',\n",
       " 'Tom não vai acreditar em mim.',\n",
       " 'Tom não vai revelar nomes.',\n",
       " 'Tom não vai entender.',\n",
       " 'O que você vai fazer agora?',\n",
       " 'O que você vai fazer lá?',\n",
       " 'Quando você vai chegar?',\n",
       " 'Quando você vai se aposentar?',\n",
       " 'Quando você vai voltar?',\n",
       " 'Quem vai dirigir?',\n",
       " 'Quem vai estar lá?',\n",
       " 'Por que você não vai?',\n",
       " 'O Tom vai comer com a gente?',\n",
       " 'O Tom vai comer conosco?',\n",
       " 'Você vai de trem?',\n",
       " 'Você vai com Tom?',\n",
       " 'Você vai falar com o Tom?',\n",
       " 'Você vai me esperar?',\n",
       " 'Você vai esperar por mim?',\n",
       " 'Você não vai acreditar em mim.',\n",
       " 'Você vai encontrar alguém.',\n",
       " 'Você vai superar isso.',\n",
       " 'Você vai ficar bem logo.',\n",
       " 'Você vai esperar?',\n",
       " 'Você vai conosco?',\n",
       " 'Você vai lá com frequência?',\n",
       " 'O Tom vai à igreja?',\n",
       " 'Vai ficar tudo bem.',\n",
       " 'Oi, como vai o negócio?',\n",
       " 'Oi, como você vai?',\n",
       " 'Oi! Como vai você?',\n",
       " 'Quanto tempo vai levar?',\n",
       " 'Como você vai para casa?',\n",
       " 'Como você vai ajudar o Tom?',\n",
       " 'Como vai a sua mulher?',\n",
       " 'Sei que vai voltar.',\n",
       " 'Eu acho que vai ficar bem.',\n",
       " 'O Tom vai ficar bem?',\n",
       " 'O Tom vai com você?',\n",
       " 'Provavelmente vai chover.',\n",
       " 'Não vai durar para sempre.',\n",
       " 'Não vai parar de chover.',\n",
       " 'Não vai demorar muito.',\n",
       " 'O dia vai ser quente amanhã.',\n",
       " 'Vai chover, com certeza.',\n",
       " 'Só vai melhorar.',\n",
       " 'Vai ser bom.',\n",
       " 'Meu gato vai amar isso.',\n",
       " 'Ninguém vai interferir.',\n",
       " 'Ninguém vai impedir.',\n",
       " 'Ela tem certeza de que vai conseguir.',\n",
       " 'Isso vai impressionar o Tom.',\n",
       " 'Dizem que vai chover.',\n",
       " 'Tom vai para a cama cedo.',\n",
       " 'O Tom vai ficar bem.',\n",
       " 'O Tom vai fazer isso.',\n",
       " 'Tom vai dormir.',\n",
       " 'Tom vai ser um professor.',\n",
       " 'Tom vai ser professor.',\n",
       " 'Tom vai confirmar isso.',\n",
       " 'Tom vai perdoar a Mary.',\n",
       " 'O Tom provavelmente vai concordar.',\n",
       " 'O Tom vai pagar por aquilo.',\n",
       " 'Tom vai jogar segunda-feira.',\n",
       " 'O Tom vai concordar com certeza.',\n",
       " 'Tom vai falar com Mary.',\n",
       " 'O Tom não vai ser punido.',\n",
       " 'Tom não vai com você.',\n",
       " 'Tom não vai convosco.',\n",
       " 'Tom não vai com o senhor.',\n",
       " 'Tom não vai com os senhores.',\n",
       " 'O Tom não vai esperar por mim.',\n",
       " 'O Tom não vai me esperar.',\n",
       " 'O Tom não vai esperar por nós.',\n",
       " 'O Tom não vai esperar pela gente.',\n",
       " 'O que o Tom vai fazer então?',\n",
       " 'O que vai acontecer com o Tom?',\n",
       " 'O que vai acontecer com você?',\n",
       " 'Como vai ser?',\n",
       " 'Quando você vai para a cama?',\n",
       " 'Aonde você vai?',\n",
       " 'Quem vai primeiro?',\n",
       " 'Em quem você vai votar?',\n",
       " 'Por que você não vai para casa?',\n",
       " 'Por que você vai me contar?',\n",
       " 'O Tom vai estar aqui em breve?',\n",
       " 'Vai chover amanhã?',\n",
       " 'Você vai me dar um pouco?',\n",
       " 'Você vai me dar alguns?',\n",
       " 'Você vai ficar em casa?',\n",
       " 'Você vai parar de falar?',\n",
       " 'Você vai viajar sozinho?',\n",
       " 'Você vai experimentar isso?',\n",
       " 'Você vai ficar em casa.',\n",
       " 'Você vai se acostumar.',\n",
       " 'Você vai receber o seu dinheiro.',\n",
       " 'Você vai perder o trem.',\n",
       " 'Você nunca vai estar sozinho.',\n",
       " 'Você nunca vai me pegar.',\n",
       " 'Você vai ficar bem.',\n",
       " 'Você vai rir.',\n",
       " 'Você vai ficar bem?',\n",
       " 'Você vai fazer isso?',\n",
       " 'Você não vai?',\n",
       " 'Você acha que isso vai caber?',\n",
       " 'Você vai em casa com frequência?',\n",
       " 'Você vai para casa com frequência?',\n",
       " 'Tudo vai mudar.',\n",
       " 'Ele vai com frequência a Tóquio.',\n",
       " 'Ele vai voltar logo.',\n",
       " 'Ele não vai passar no teste.',\n",
       " 'Como vai o trabalho?',\n",
       " 'Quanto tempo você vai ficar?',\n",
       " 'Eu acho que vai fazer sol.',\n",
       " 'Eu acho que vai estar ensolarado.',\n",
       " 'Acho que isto vai funcionar.',\n",
       " 'Eu tenho certeza de que o Tom vai ligar.',\n",
       " 'Tenho certeza de que o Tom vai ligar.',\n",
       " 'Ele vai nos ajudar?',\n",
       " 'Vai ficar bem?',\n",
       " 'Não vai doer.',\n",
       " 'Isso não vai parar de sangrar.',\n",
       " 'Não vai parar de sangrar.',\n",
       " 'Com certeza vai ser divertido.',\n",
       " 'Isso com certeza vai ser divertido.',\n",
       " 'Com certeza isso vai ser divertido.',\n",
       " 'Vai ser ótimo.',\n",
       " 'Não vai nevar.',\n",
       " 'Meu pai vai me matar.',\n",
       " 'O meu pai vai me matar.',\n",
       " 'Ninguém vai acreditar em mim.',\n",
       " 'Ninguém vai acreditar em nós.',\n",
       " 'Ninguém vai acreditar na gente.',\n",
       " 'Nos diga o que vai acontecer.',\n",
       " 'Nos conte o que vai acontecer.',\n",
       " 'Nos digam o que vai acontecer.',\n",
       " 'Isso nunca vai acontecer.',\n",
       " 'Essa janela não vai abrir.',\n",
       " 'Isto não vai doer nada.',\n",
       " 'Tom não vai poder trabalhar de noite.',\n",
       " 'Tom não vai poder trabalhar essa noite.',\n",
       " 'Tom vai se casar.',\n",
       " 'O Tom vai para Boston.',\n",
       " 'Tom vai dizer não.',\n",
       " 'Tom vai partir às 2:30.',\n",
       " 'Tom vai ensinar francês.',\n",
       " 'Tom não vai ganhar.',\n",
       " 'Tom não vai vencer.',\n",
       " 'O Tom não vai ganhar.',\n",
       " 'O Tom disse que vai fazer.',\n",
       " 'O Tom disse que vai fazer isso.',\n",
       " 'O Tom disse que ele vai fazer.',\n",
       " 'O Tom disse que ele vai fazer isso.',\n",
       " 'O Tom diz que não vai votar.',\n",
       " 'O Tom diz que vai fazer.',\n",
       " 'O Tom diz que vai fazer isso.',\n",
       " 'O Tom diz que ele vai fazer.',\n",
       " 'O Tom diz que ele vai fazer isso.',\n",
       " 'Tom vai se adaptar rapidamente.',\n",
       " 'Tom vai te desafiar.',\n",
       " 'Tom vai encontrar alguém.',\n",
       " 'Tom vai fazer as camas.',\n",
       " 'Tom vai me encontrar mais tarde.',\n",
       " 'Tom vai precisar da nossa ajuda.',\n",
       " 'Tom nunca vai encontrar.',\n",
       " 'Tom nunca vai se recuperar.',\n",
       " 'Tom nunca vai sobreviver.',\n",
       " 'Tom não vai sobreviver nunca.',\n",
       " 'Tom vai concorrer a prefeito.',\n",
       " 'O Tom vai cantar para a Mary.',\n",
       " 'O Tom vai ficar com você.',\n",
       " 'O Tom vai esperar pela Mary.',\n",
       " 'O Tom não vai comprar nada.',\n",
       " 'O que o Tom vai fazer com isso?',\n",
       " 'O que é que o Tom vai fazer com isso?',\n",
       " 'O que você vai fazer com isso?',\n",
       " 'O que o Tom vai fazer?',\n",
       " 'O que é que o Tom vai fazer?',\n",
       " 'O que vai acontecer?',\n",
       " 'Quando o Tom vai chegar em casa?',\n",
       " 'Quando você vai chegar em casa?',\n",
       " 'Para onde vai este ônibus?',\n",
       " 'Com quem você vai?',\n",
       " 'Quem vai fazer isso?',\n",
       " 'Por que você não vai sozinho?',\n",
       " 'Por que você não vai sozinha?',\n",
       " 'Por que você não vai primeiro?',\n",
       " 'Por que você não vai lá?',\n",
       " 'Por que você não vai falar com Tom?',\n",
       " 'Alguém mais vai vir?',\n",
       " 'Aquilo vai acontecer de novo?',\n",
       " 'Isso vai acontecer de novo?',\n",
       " 'Vai acontecer de novo?',\n",
       " 'Você vai dançar comigo?',\n",
       " 'Você ainda vai me ajudar?',\n",
       " 'Você vai nadar com o Tom?',\n",
       " 'Você vai ficar bem.',\n",
       " 'Você vai se machucar.',\n",
       " 'Você não vai, vai?',\n",
       " 'Você não vai, vai?',\n",
       " 'Você vai ajudar, não vai?',\n",
       " 'Você vai ajudar, não vai?',\n",
       " 'Você vai precisar de dinheiro.',\n",
       " 'Você vai adorar isto.',\n",
       " 'Você vai me bater?',\n",
       " 'Tem certeza que isso vai funcionar?',\n",
       " 'Ou vai o Tom ou vou eu.',\n",
       " 'Vai tudo bem.',\n",
       " 'Tudo vai ficar bem.',\n",
       " 'Vai ficar tudo bem.',\n",
       " 'Ele vai visitar o tio dele.',\n",
       " 'Ele não vai nos deixar sozinhos.',\n",
       " 'Ele não vai nos deixar sozinhas.',\n",
       " 'Ele vai ser um bom marido.',\n",
       " 'Ele vai tomar conta disso.',\n",
       " 'Ele vai amar isto.',\n",
       " 'Como você vai para a escola?',\n",
       " 'Como você vai à escola?',\n",
       " 'Como vai a sua família?',\n",
       " 'Como vai a sua avó?',\n",
       " 'Quanto isso vai custar?',\n",
       " 'Como isso vai acabar?',\n",
       " 'Acho que isso não vai importar.',\n",
       " 'Eu acho que você vai gostar bastante.',\n",
       " 'Acho que vai chover.',\n",
       " 'Estou achando que vai chover.',\n",
       " 'Estou certo que você vai conseguir.',\n",
       " 'Se eu não for, quem vai?',\n",
       " 'O Tom vai fazer isso?',\n",
       " 'O Tom vai nos ajudar?',\n",
       " 'A sua família vai indo bem?',\n",
       " 'A sua família vai bem?',\n",
       " 'Não vai mudar nada.',\n",
       " 'Vai dar tudo certo.',\n",
       " 'Vai ficar difícil.',\n",
       " 'Vai piorar.',\n",
       " 'Vai ficar pior.',\n",
       " 'Certifique-se de que o Tom vai receber isto.',\n",
       " 'Esteja seguro de que ninguém vai entrar.',\n",
       " 'Mamãe vai nos comprar um cachorrinho.',\n",
       " 'Ninguém vai comigo.',\n",
       " 'Ninguém vai acreditar nele.',\n",
       " 'Ninguém vai acreditar em você.',\n",
       " 'Ninguém vai acreditar em vocês.',\n",
       " 'Conte ao Tom o que você vai fazer.',\n",
       " 'Isso vai ser muito divertido.',\n",
       " 'Este nó não vai segurar.',\n",
       " 'Isto vai te manter aquecido.',\n",
       " 'Isto vai mantê-la aquecida.',\n",
       " 'O Tom vai para Havard.',\n",
       " 'Tom vai estar ocupado.',\n",
       " 'O Tom vai ficar bem.',\n",
       " 'O Tom vai fazer isso.',\n",
       " 'Tom vai fazer isto.',\n",
       " 'O Tom vai nos encontrar,',\n",
       " 'Tom vai me ajudar.',\n",
       " 'Tom vai fazer isso.',\n",
       " 'O Tom vai sentir a minha falta.',\n",
       " 'Tom vai sobreviver.',\n",
       " 'Tom não vai se importar.',\n",
       " 'Tom não vai ajudar.',\n",
       " 'Tom não vai se importar.',\n",
       " 'Tom não vai cantar.',\n",
       " 'Tom não vai parar.',\n",
       " 'Tom diz que ele não vai.',\n",
       " 'Tom diz que não vai.',\n",
       " 'Tom vai vir depois de tudo.',\n",
       " 'Tom vai descer em breve.',\n",
       " 'Tom provavelmente vai concordar.',\n",
       " 'Tom vai voltar às 14:30.',\n",
       " 'Tom vai contar a verdade.',\n",
       " 'Tom vai tentar me impedir.',\n",
       " 'O Tom não vai desconfiar.',\n",
       " 'Tom não vai tolerar isso.',\n",
       " 'O que vai acontecer com o Tom?',\n",
       " 'Quanto a viagem vai custar?',\n",
       " 'Quanto vai custar a viagem?',\n",
       " 'A viagem vai custar quanto?',\n",
       " 'O que o Tom vai fazer a respeito?',\n",
       " 'O que o Tom vai fazer amanhã?',\n",
       " 'O que você vai fazer amanhã?',\n",
       " 'Amanhã o que você vai fazer?',\n",
       " 'O que você vai fazer com o Tom?',\n",
       " 'O que você vai fazer?',\n",
       " 'Quando é que você vai voltar?',\n",
       " 'Quando você vai voltar?',\n",
       " 'Aonde vai este livro?',\n",
       " 'Quem vai dar a festa?',\n",
       " 'Quem vai estar lá?',\n",
       " 'Quem vai impedir o Tom?',\n",
       " 'Por que você não vai primeiro?',\n",
       " 'Por que você não vai nos deixar entrar?',\n",
       " 'Ele vai, algum dia, me perdoar?',\n",
       " 'Será que vai fazer calor amanhã?',\n",
       " 'Vai fazer calor amanhã?',\n",
       " 'Isso vai mudar as coisas?',\n",
       " 'Você vai estar aqui na segunda?',\n",
       " 'Você vai me ajudar?',\n",
       " 'Você vai me dar uma mão?',\n",
       " 'Você vai perder o trem.',\n",
       " 'Você não vai se interessar.',\n",
       " 'Você não vai acreditar nisso.',\n",
       " 'Você não vai acreditar em mim.',\n",
       " 'Você vai mudar de ideia.',\n",
       " 'Você vai se meter em encrenca.',\n",
       " 'Você vai superar isso.',\n",
       " 'Você vai passar um sufoco.',\n",
       " 'Você vai ter de confiar em mim.',\n",
       " 'Você vai ter que confiar em mim.',\n",
       " 'Você vai entender depois.',\n",
       " 'Você vai querer ver isto.',\n",
       " 'Você vai ficar bem.',\n",
       " 'Você vai se atrasar.',\n",
       " 'Você vai se sair bem.',\n",
       " 'Você vai sentir a minha falta.',\n",
       " 'Você não vai morrer.',\n",
       " 'Você vai fazer isso?',\n",
       " 'Você vai desistir?',\n",
       " 'Você vai me ajudar?',\n",
       " 'Você vai me beijar?',\n",
       " 'Você vai sentir falta?',\n",
       " 'Você não vai votar?',\n",
       " 'Você não vai comigo?',\n",
       " 'Pergunte ao Tom se ele vai fazer isso.',\n",
       " 'Ele vai à escola de ônibus.',\n",
       " 'Ele vai de ônibus para a escola.',\n",
       " 'Ele, raramente, vai à igreja.',\n",
       " 'Ele vai estar ocupado amanhã.',\n",
       " 'Ele vai estar livre amanhã.',\n",
       " 'Ele vai acabar na cadeia.',\n",
       " 'Ele vai no teu lugar.',\n",
       " 'Ei, aonde vai?',\n",
       " 'Como vai a escola?',\n",
       " 'Como ele vai para a escola?',\n",
       " 'Como ele vai à escola?',\n",
       " 'Como vai o Tom?',\n",
       " 'Como vai sua família?',\n",
       " 'Isso vai me custar quanto?',\n",
       " 'Quanto você vai me pagar?',\n",
       " 'Quanto você vai nos pagar?',\n",
       " 'Em quanto tempo Tom vai chegar?',\n",
       " 'Como o Tom vai fazer isso?',\n",
       " 'Como vai o trabalho?',\n",
       " 'Como vai na escola?',\n",
       " 'Eu acho que não vai nevar.',\n",
       " 'Eu acho que Tom vai gostar.',\n",
       " 'Acho que vai ficar tudo bem.',\n",
       " 'Tenho certeza de que Tom vai ficar tímido.',\n",
       " 'Eu tenho certeza de que Tom vai ficar tímido.',\n",
       " 'Tenho certeza de que você vai gostar de Tom.',\n",
       " 'Estou querendo saber quem vai ganhar.',\n",
       " 'Tom vai estar lá?',\n",
       " 'O Tom vai estar lá?',\n",
       " 'Parece que vai chover.',\n",
       " 'Parece que vai chover.',\n",
       " 'Não vai doer, eu prometo.',\n",
       " 'Isso vai acontecer com você também.',\n",
       " 'Isso vai levar alguns segundos.',\n",
       " 'Vai de encontro a minha religião.',\n",
       " 'Vai ser incrível.',\n",
       " 'Nunca vai durar.',\n",
       " 'Vamos ver o que vai acontecer.',\n",
       " 'Meu pai vai de carro para o trabalho.',\n",
       " 'Meu pai não vai deixar.',\n",
       " 'O meu pai não vai permitir.',\n",
       " 'Ninguém vai acreditar neles.',\n",
       " 'Ninguém vai acreditar nelas.',\n",
       " 'Ninguém vai nos atrasar.',\n",
       " 'Ninguém vai acreditar nisso.',\n",
       " 'Ela vai acabar falhando.',\n",
       " 'Ela não vai desistir à toa.',\n",
       " 'Isto vai ser fácil.',\n",
       " 'Isso não vai dar certo.',\n",
       " 'Tom não vai à escola.',\n",
       " 'Tom vai trabalhar às 7:30.',\n",
       " 'Tom vai comprar um computador.',\n",
       " 'Tom vai ficar zangado.',\n",
       " 'O Tom vai ser feliz.',\n",
       " 'O Tom vai estar pronto.',\n",
       " 'O Tom vai estar lá.',\n",
       " 'Tom vai te amar.',\n",
       " 'Tom vai sentir sua falta.',\n",
       " 'Tom vai ficar com saudades de você.',\n",
       " 'Tom vai precisar de um.',\n",
       " 'Tom vai precisar de uma.',\n",
       " 'Tom não vai argumentar.',\n",
       " 'Tom não vai discutir.',\n",
       " 'Tom nunca vai à igreja.',\n",
       " 'Tom diz que não vai vir.',\n",
       " 'Tom vai sempre amar-te.',\n",
       " 'Tom vai amar-te sempre.',\n",
       " 'Tom vai amá-la sempre.',\n",
       " 'Tom vai sempre amá-la.',\n",
       " 'Tom vai amar-vos sempre.',\n",
       " 'Tom vai sempre amar-vos.',\n",
       " 'Tom sempre vai vos amar.',\n",
       " 'Tom vai vos amar sempre.',\n",
       " 'Tom vai comprar aquilo, né?',\n",
       " 'Tom vai comprar isso, certo?',\n",
       " 'Tom vai ter pesadelos.',\n",
       " 'Tom vai ter que fazer isso.',\n",
       " 'Tom vai ter de fazer isso.',\n",
       " 'Tom vai lhe emprestar um livro.',\n",
       " 'Tom vai precisar de mais dinheiro.',\n",
       " 'Tom vai voltar amanhã.',\n",
       " 'Tom vai tentar me impedir.',\n",
       " 'Tom vai tentar te impedir.',\n",
       " 'Tom não vai te fazer feliz.',\n",
       " 'O Tom não vai jogar esse ano.',\n",
       " 'O que você vai fazer?',\n",
       " 'O que você vai fazer?',\n",
       " 'A que horas você vai para casa?',\n",
       " 'O que o Tom vai fazer com isso?',\n",
       " 'O que você vai comer?',\n",
       " 'O que você vai dizer?',\n",
       " 'Quando a loja vai abrir?',\n",
       " 'Quando você vai aprender alguma vez?',\n",
       " 'Afinal, quando você vai aprender?',\n",
       " 'O Tom vai comprar aquilo para a gente?',\n",
       " 'Você vai enviar por correio?',\n",
       " 'Você vai passar um sufoco.',\n",
       " 'Você vai passar uns maus bocados.',\n",
       " 'Você vai ter de vir aqui.',\n",
       " 'Você vai se divertir.',\n",
       " 'Você vai gostar do Tom.',\n",
       " 'Vai para casa de autocarro?',\n",
       " 'Você vai estar lá?',\n",
       " 'Você vai comprar isso?',\n",
       " 'Você vai comer isso?',\n",
       " 'Você vai comer isto?',\n",
       " 'Você vai para lá?',\n",
       " 'Você vai usar isso?',\n",
       " 'Você vai usar isto?',\n",
       " 'Tem certeza que isso vai funcionar?',\n",
       " 'Você tem certeza de que isso vai funcionar?',\n",
       " 'Vocês têm certeza de que isso vai funcionar?',\n",
       " 'Tem certeza que isso vai funcionar?',\n",
       " 'Você não vai dançar?',\n",
       " 'Você não vai fazer isso?',\n",
       " 'Você não vai dormir?',\n",
       " 'Você acha que vai funcionar?',\n",
       " 'Você acha que vai funcionar?',\n",
       " 'Ele vai trabalhar de ônibus?',\n",
       " 'Ele vai para o trabalho de ônibus?',\n",
       " 'Ele vai voltar às quatro.',\n",
       " 'Ele vai agarrar em qualquer palha.',\n",
       " 'Ele vai lamentar isto.',\n",
       " 'Ela vai se arrepender disso.',\n",
       " 'Como Tom vai para a escola?',\n",
       " 'Eu sei que vai demorar um pouco.',\n",
       " 'Eu te prometo que você vai ser feliz.',\n",
       " 'Eu acho que isso vai funcionar.',\n",
       " 'Eu acho que você vai gostar.',\n",
       " 'Eu me pergunto o que ele vai dizer.',\n",
       " 'Eu imagino o que ele vai dizer.',\n",
       " 'Me pergunto o que ele vai dizer.',\n",
       " 'Vai chover hoje?',\n",
       " 'Não vai ser fácil.',\n",
       " 'Isso não vai ser fácil.',\n",
       " 'Vai ficar muito caro.',\n",
       " 'Vai parar de chover logo.',\n",
       " 'Não vai demorar muito.',\n",
       " 'Vai ser melhor da próxima vez.',\n",
       " 'Não vai ser fácil.',\n",
       " 'Não vai demorar.',\n",
       " 'Minha banda vai tocar hoje à noite.',\n",
       " 'Meu filho não vai me ouvir.',\n",
       " 'Ninguém vai falar comigo.',\n",
       " 'Ninguém vai fazer isso.',\n",
       " 'Ninguém vai te ver.',\n",
       " 'Nada vai acontecer.',\n",
       " 'Isso não vai mudar nada.',\n",
       " 'Isso não vai resolver nada.',\n",
       " 'Isso vai colocá-lo em risco.',\n",
       " 'O jogo já vai começar.',\n",
       " 'O sol vai-se levantar em breve.',\n",
       " 'Tom vai à escola de ônibus.',\n",
       " 'Tom vai para a escola de carro.',\n",
       " 'Tom vai ao trabalho de trem.',\n",
       " 'O Tom vai comprar uma casa nova.',\n",
       " 'Tom vai ficar com medo.',\n",
       " 'O Tom vai matar a Mary.',\n",
       " 'Tom vai gostar disso.',\n",
       " 'Tom vai amar isto.',\n",
       " 'O Tom vai adorar isso.',\n",
       " 'Tom vai sentir falta de Mary.',\n",
       " 'O Tom vai ficar com saudade da Mary.',\n",
       " 'Tom vai precisar de ajuda.',\n",
       " 'Tom vai ficar aqui.',\n",
       " 'Tom não vai fazer isso.',\n",
       " 'O Tom não vai para Boston.',\n",
       " 'O Tom não vai pra Boston.',\n",
       " 'Tom não vai dizer não.',\n",
       " 'O Tom nunca vai a pé para a escola.',\n",
       " 'O Tom raramente vai a Boston.',\n",
       " 'Tom raramente vai à igreja.',\n",
       " 'Tom vai ser um bom pai.',\n",
       " 'Tom vai se atrasar um pouco.',\n",
       " 'Tom vai estar aqui a semana toda.',\n",
       " 'Tom vai acreditar em qualquer coisa.',\n",
       " 'O Tom vai continuar esperando.',\n",
       " 'O Tom vai consertar isso para você.',\n",
       " 'Tom vai nos manter informados.',\n",
       " 'Tom nunca vai entender.',\n",
       " 'Tom vai ser pai em breve.',\n",
       " 'Tom em breve vai ser pai.',\n",
       " 'O Tom não vai te fazer nenhum mal.',\n",
       " 'O Tom não vai fazer a você nenhum mal.',\n",
       " 'O Tom não vai fazer nenhum mal a você.',\n",
       " 'O Tom não vai fazer-lhe nenhum mal.',\n",
       " 'O Tom não vai fazer-te nenhum mal.',\n",
       " 'O Tom não vai fazer a vocês nenhum mal.',\n",
       " 'O Tom não vai fazer-lhes nenhum mal.',\n",
       " 'O Tom não vai fazer-vos nenhum mal.',\n",
       " 'O Tom não vai precisar disso.',\n",
       " 'Tom não vai falar sobre isso.',\n",
       " 'O Tom não vai entender isso.',\n",
       " 'Temos certeza de que você vai ficar bom.',\n",
       " 'O que você vai fazer no domingo?',\n",
       " 'O que você vai dizer?',\n",
       " 'O que você vai ver?',\n",
       " 'A que horas ele vai estar aqui?',\n",
       " 'O que você vai fazer amanhã?',\n",
       " 'O que você vai fazer esta noite?',\n",
       " 'O que você vai fazer hoje à noite?',\n",
       " 'Quando o jantar vai estar pronto?',\n",
       " 'Quando você vai se casar?',\n",
       " 'Quando você vai tomar banho?',\n",
       " 'Aonde vai ter essa estrada?',\n",
       " 'Onde vai ser o show?',\n",
       " 'Onde você vai ficar?',\n",
       " 'Por que não vai dormir?',\n",
       " 'Por que você não vai comer com a gente?',\n",
       " 'Será que em algum momento vai parar de chover?',\n",
       " 'Você não vai ficar para o jantar?',\n",
       " 'Você vai se machucar.',\n",
       " 'Você não vai se decepcionar.',\n",
       " 'Você não vai precisar disso.',\n",
       " 'Você vai me ajudar, não vai?',\n",
       " 'Você vai me ajudar, não vai?',\n",
       " 'Você vai ver a diferença.',\n",
       " 'Você vai ser famoso.',\n",
       " 'Você vai adorar isso.',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"words_to_phrases.pickle\", \"rb\")\n",
    "words_to_phrases = pickle.load(pickle_in)\n",
    "words_to_phrases['vai']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing a User's Vocabulary Knowledge\n",
    "We want to maintain a database representing how familiar a given user is with a given word. Let us say that a user can be completely unfamiliar with a word (let's call this 0% familiar), or completely familiar with a word (let's call this 100% familiar). Let us also assume that the average user will be more familiar with words which occur more frequently. In the following \"scale_frequency\" function, we define a method of transforming the frequency of each word into a level of familiarity with each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scaled frequency which represents the familiarity of the user with each word as a percentage.\n",
    "def scale_frequency(freq=freq, n=None, level=\"functional\"):\n",
    "    num = 1\n",
    "    if not n:\n",
    "        # Beginner: first 100 words have minimum 50% familiarity\n",
    "        if level == \"beginner\":\n",
    "            num = 100\n",
    "        # Functional: first 500 words have minimum 50% familiarity \n",
    "        elif level == \"functional\":\n",
    "            num = 500\n",
    "        # Conversational: first 1000 words have minimum 50% familiarity\n",
    "        elif level == \"conversational\":\n",
    "            num = 1000\n",
    "        # Advanced: first 4000 words have minimum 50% familiarity\n",
    "        elif level == \"advanced\":\n",
    "            num = 4000\n",
    "        # Fluent: first 10000 words have minimum 50% familiarity\n",
    "        elif level == \"fluent\":\n",
    "            num = 10000\n",
    "    else:\n",
    "        num = n\n",
    "        \n",
    "    # This scales the whole list so that the num-th word has probability 0.5.\n",
    "    # Tanh behaves in such a way that numbers in [0,1] stay more or less themselves,\n",
    "    # whereas numbers much larger than zero are squashed into the interval [0,1].\n",
    "    return np.tanh((0.5/freq[num-1])*np.array(freq)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb7c3e8ea30>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize probability distribution\n",
    "x = np.linspace(0, len(vocab), len(vocab))\n",
    "y = scale_frequency()\n",
    "\n",
    "plt.ylim(top=max(y), bottom=0)\n",
    "plt.xlim(left=0, right=1.25*1000)\n",
    "plt.plot(x, y, \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we manage the data stored for different users of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Exercise Difficulty\n",
    "In order to control the difficulty of the exercises presented to the user, we will choose words with different levels of familiarity with different probabilities. In other words, at a medium difficulty level, we want to focus on 50% familiarity words, so that high familiarity and low familiarity words are less likely to show up than words of moderate familiarity, words which are at the cusp of being known. We use a beta distribution over [0,1] to get this effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(arr, m=0.5, inv_v=0.05, flatness=0.01):\n",
    "    if flatness >= 1:\n",
    "        return np.ones(len(arr)).tolist()\n",
    "        \n",
    "    a = m/inv_v; b = (1 - m)/inv_v\n",
    "    distr = beta.pdf(arr, a, b)\n",
    "    \n",
    "    if flatness <= 0:\n",
    "        return distr\n",
    "    \n",
    "    upper = max(distr)\n",
    "    integral = sum(distr)\n",
    "    baseline = (upper/((1/flatness)-1))*np.ones(len(arr))\n",
    "    new_integral = integral + sum(baseline)\n",
    "    return (distr + baseline)*(integral/new_integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb7bbdbde80>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize probability distribution\n",
    "x = np.linspace(0, 1.0, 100)\n",
    "y = get_distribution(x)\n",
    "\n",
    "plt.ylim(top=1.1*max(y), bottom=0)\n",
    "plt.plot(x, y, \"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Knowledge\n",
    "Every time an exercise is undertaken, we need to increase the familiarity of a word which is correctly identified, and decrease the familiarity of a word which is incorrectly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = learning rate; fr = forgetting rate\n",
    "def update(arr, index, correct, lr=0.3, fr=0.3):\n",
    "    if correct:\n",
    "        # Increase its probability\n",
    "        arr[index] += (1-arr[index])*lr\n",
    "    else:\n",
    "        # Decrease its probability\n",
    "        arr[index] -= arr[index]*fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_users():\n",
    "    users = {}\n",
    "    users[\"Default\"] = scale_frequency()\n",
    "    pickle_out = open(\"users.pickle\", \"wb\")\n",
    "    pickle.dump(users, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"users.pickle\", \"rb\")\n",
    "users = pickle.load(pickle_in)\n",
    "current_user = \"Default\"\n",
    "user_levels = [\"beginner\", \"functional\", \"conversational\", \"advanced\", \"fluent\"]\n",
    "\n",
    "# Changes the current user\n",
    "def change_user(user):\n",
    "    global current_user\n",
    "    if user in users.keys():\n",
    "        current_user = user\n",
    "        return True\n",
    "    else:\n",
    "        print('This user name does not exist.')\n",
    "        return False\n",
    "\n",
    "# Add a new user\n",
    "def add_user(user, distr=freq, n=None, level=\"functional\"):\n",
    "    global users\n",
    "    global current_user\n",
    "    if user not in users.keys():\n",
    "        if level in user_levels:\n",
    "            current_user = user\n",
    "            users[user] = scale_frequency(freq=distr, n=n, level=level)\n",
    "\n",
    "            # Save changes.\n",
    "            pickle_out = open(\"users.pickle\", \"wb\")\n",
    "            pickle.dump(users, pickle_out)\n",
    "            pickle_out.close()\n",
    "\n",
    "            # Update local version of users.\n",
    "            pickle_in = open(\"users.pickle\", \"rb\")\n",
    "            users = pickle.load(pickle_in)\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            print('This is not a valid level.')\n",
    "            return False\n",
    "    else:\n",
    "        print('This user name already exists.')\n",
    "        return False\n",
    "    \n",
    "def delete_user(user):\n",
    "    global users\n",
    "    if user == current_user:\n",
    "        print('Cannot delete current user.')\n",
    "        return False\n",
    "    if user not in users.keys():\n",
    "        print('User does not exist.')\n",
    "        return False\n",
    "    else:\n",
    "        del users[user]\n",
    "                \n",
    "        # Save changes.\n",
    "        pickle_out = open(\"users.pickle\", \"wb\")\n",
    "        pickle.dump(users, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # Update local version of users.\n",
    "        pickle_in = open(\"users.pickle\", \"rb\")\n",
    "        users = pickle.load(pickle_in)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "def list_users():\n",
    "    print(\"+-----------+\")\n",
    "    print(\"| USER LIST |\")\n",
    "    print(\"+-----------+\")\n",
    "    max_user_ln = max([len(key) for key in users.keys()])\n",
    "    max_level_ln = max([len(lvl) for lvl in user_levels])\n",
    "    for user in users.keys():\n",
    "        level = calculate_level(users[user])\n",
    "        print('  '+user+':'+' '*(1+max_user_ln+max_level_ln-len(user)-len(level))+level)\n",
    "    print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Snippets of Input Text\n",
    "We save copied-and-pasted snippets of Portuguese text in bag-of-words form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a method for initializing the first snippets data structure, where we save the count profiles\n",
    "# of snippets of text which have been saved to serve as a basis for training exercises.\n",
    "def initialize_snippets():\n",
    "    snippets = {}\n",
    "    pickle_out = open(\"snippets.pickle\", \"wb\")\n",
    "    pickle.dump(snippets, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "# This is a method for initializing the first snippets data structure, where we save the snippets \n",
    "# in their original text form.\n",
    "def initialize_original_snippets():\n",
    "    original_snippets = {}\n",
    "    pickle_out = open(\"original_snippets.pickle\", \"wb\")\n",
    "    pickle.dump(original_snippets, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(path):\n",
    "    if os.path.exists(file_path):\n",
    "        snippet = open(path, encoding='UTF-8').read()\n",
    "        return snippet\n",
    "    else:\n",
    "        print(\"This file path does not exist.\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in data saved from previous sessions\n",
    "pickle_in = open(\"snippets.pickle\", \"rb\")\n",
    "snippets = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"original_snippets.pickle\", \"rb\")\n",
    "original_snippets = pickle.load(pickle_in)\n",
    "\n",
    "# This converts a piece of (mostly) Portuguese text into what is essentially a bag of words interpretation.\n",
    "# We keep a dictionary of the (previously known, non-named-entity) words and their counts in the text.\n",
    "def convert_snippet(input):\n",
    "    # Exclude local named entities.\n",
    "    ne = rudimentary_NER(phrases=[input])\n",
    "    local_count = Counter()\n",
    "    \n",
    "    for w in words_only(input).split(' '):\n",
    "        if w not in ne:\n",
    "            if w.lower() in vocab:\n",
    "                local_count[vocab.index(w.lower())] += 1\n",
    "    \n",
    "    return local_count   \n",
    "\n",
    "def add_snippet(input, title):   \n",
    "    global snippets\n",
    "    global original_snippets\n",
    "    \n",
    "    if len(input) == 0:\n",
    "        print(\"This snippet is empty.\")\n",
    "        return False\n",
    "    \n",
    "    if title in snippets.keys():\n",
    "        print(\"This snippet name is already in use. Please try another snippet name.\")\n",
    "        return False\n",
    "        \n",
    "    # Update snippets.\n",
    "    local_count = convert_snippet(input)\n",
    "    snippets[title] = dict(local_count)\n",
    "    \n",
    "    # Save changes.\n",
    "    pickle_out = open(\"snippets.pickle\", \"wb\")\n",
    "    pickle.dump(snippets, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    # Update local version of snippets.\n",
    "    pickle_in = open(\"snippets.pickle\", \"rb\")\n",
    "    snippets = pickle.load(pickle_in)\n",
    "    \n",
    "    # Update original_snippets.\n",
    "    original_snippets[title] = input\n",
    "    \n",
    "    # Save changes.\n",
    "    pickle_out = open(\"original_snippets.pickle\", \"wb\")\n",
    "    pickle.dump(original_snippets, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    # Update local version of original_snippets.\n",
    "    pickle_in = open(\"original_snippets.pickle\", \"rb\")\n",
    "    original_snippets = pickle.load(pickle_in)\n",
    "    \n",
    "    return True\n",
    "\n",
    "def delete_snippet(title):\n",
    "    global snippets\n",
    "    global original_snippets\n",
    "    \n",
    "    if title not in snippets.keys():\n",
    "        print(\"This snippet name is not in use. Please try an existing snippet name.\")\n",
    "        return False\n",
    "    else:    \n",
    "        # Update snippets.\n",
    "        del snippets[title]\n",
    "\n",
    "        # Save changes.\n",
    "        pickle_out = open(\"snippets.pickle\", \"wb\")\n",
    "        pickle.dump(snippets, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # Update local version of snippets.\n",
    "        pickle_in = open(\"snippets.pickle\", \"rb\")\n",
    "        snippets = pickle.load(pickle_in)\n",
    "        \n",
    "        # This simply accounts for the fact that original snippets were not originally stored\n",
    "        if title in original_snippets.keys():\n",
    "            # Update original_snippets.\n",
    "            del original_snippets[title]\n",
    "\n",
    "            # Save changes.\n",
    "            pickle_out = open(\"original_snippets.pickle\", \"wb\")\n",
    "            pickle.dump(original_snippets, pickle_out)\n",
    "            pickle_out.close()\n",
    "\n",
    "            # Update local version of original_snippets.\n",
    "            pickle_in = open(\"original_snippets.pickle\", \"rb\")\n",
    "            original_snippets = pickle.load(pickle_in)\n",
    "\n",
    "        return True\n",
    "\n",
    "def list_snippets():\n",
    "    print(\"+--------------+\")\n",
    "    print(\"| SNIPPET LIST |\")\n",
    "    print(\"+--------------+\")\n",
    "    for snippet in snippets.keys():\n",
    "        print(\"  \"+snippet)\n",
    "    print()\n",
    "    return\n",
    "\n",
    "def print_original_snippet(snippet):\n",
    "    \n",
    "    title = '| ORIGINAL SNIPPET: '+snippet+' |'\n",
    "    print('+'+'-'*(len(title)-2)+'+')\n",
    "    print(title)\n",
    "    print('+'+'-'*(len(title)-2)+'+')\n",
    "    \n",
    "    if snippet in original_snippets.keys():\n",
    "        print(original_snippets[snippet])\n",
    "    else:\n",
    "        print('There is no original snippet text associated with this snippet name.')\n",
    "    return\n",
    "\n",
    "def print_snippet(snippet):\n",
    "    \n",
    "    title = '| SNIPPET WORDCOUNT: '+snippet+' |'\n",
    "    print('+'+'-'*(len(title)-2)+'+')\n",
    "    print(title)\n",
    "    print('+'+'-'*(len(title)-2)+'+')\n",
    "    \n",
    "    if snippet in snippets.keys():\n",
    "        snippet_dict = snippets[snippet]\n",
    "        max_word_ln = max([len(vocab[key]) for key in snippet_dict.keys()])\n",
    "        max_num_ln = max([len(str(item)) for item in snippet_dict.values()])\n",
    "        for pair in sorted(snippet_dict.items(), key=lambda item: item[1], reverse=True):\n",
    "            print('  '+vocab[pair[0]]+':'+' '*(1+max_word_ln+max_num_ln-len(vocab[pair[0]])-len(str(pair[1])))+str(pair[1]))\n",
    "            \n",
    "        print()\n",
    "    else:\n",
    "        print('There is no snippet word count associated with this snippet name.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_snippets.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the Local Importance of Words in a Snippet of Text\n",
    "Here we identify which words are most important to the text, as well as which words are least familiar to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_indices(input, user=current_user):\n",
    "    # Get the indices in order from largest to smallest local count in the document.\n",
    "    indices = [i for i, c in sorted(input.items(), key=lambda x: x[1], reverse=True)]\n",
    "    return indices\n",
    "\n",
    "\n",
    "def local_frequency(input, user=current_user): \n",
    "    local_count = [c for i, c in sorted(input.items(), key=lambda x: x[1], reverse=True)]\n",
    "    tot = sum(local_count)\n",
    "    \n",
    "    # Return the frequency of each local word with respect to the local document.\n",
    "    local_freq = [c/tot for c in local_count]\n",
    "\n",
    "    return local_freq\n",
    "\n",
    "\n",
    "def local_importance(input, user=current_user):    \n",
    "    indices = local_indices(input, user)\n",
    "    local_freq = local_frequency(input, user)\n",
    "    \n",
    "    # Importance is the ratio of the local frequency to the global frequency.\n",
    "    importance = [local_freq[i]/freq[indices[i]] for i in range(len(indices))]\n",
    "    by_importance = [ind for imp, ind in sorted(zip(importance, indices))]\n",
    "    # Rank the words locally by their importance in the document.\n",
    "    importance_rank = [by_importance.index(i)+1 for i in indices]\n",
    "    \n",
    "    return importance, importance_rank\n",
    "\n",
    "\n",
    "def local_familiarity(input, user=current_user):\n",
    "    indices = local_indices(input, user)\n",
    "    \n",
    "    # Each user's associated list is a list of that user's familiarity with each word in the vocabulary.\n",
    "    familiarity = [users[user][indices[i]] for i in range(len(indices))]\n",
    "    by_familiarity = [i for f, i in sorted(zip(familiarity, indices))]\n",
    "    # Rank the words locally by their familiarity.\n",
    "    familiarity_rank = [by_familiarity.index(i)+1 for i in indices]\n",
    "    \n",
    "    return familiarity, familiarity_rank\n",
    "\n",
    "\n",
    "def local_interest(input, user=current_user):\n",
    "    indices = local_indices(input, user)\n",
    "    \n",
    "    # Importance is the ratio of the local importance to the global importance.\n",
    "    importance, importance_rank = local_importance(input, user)\n",
    "    \n",
    "    # Each user's associated list is a list of that user's familiarity with each word in the vocabulary.\n",
    "    familiarity, familiarity_rank = local_familiarity(input, user)\n",
    "    \n",
    "    # A word is more interesting to a user if it has a higher importance and a lower familiarity.\n",
    "    # Using the ranks avoids divisions by zero and also puts importance and familiarity on a similar scale.\n",
    "    interest = [importance_rank[i]/familiarity_rank[i] for i in range(len(indices))]\n",
    "    by_interest = [ind for inr, ind in sorted(zip(interest, indices))]\n",
    "    # Rank the words locally by their interest.\n",
    "    interest_rank = [by_interest.index(i)+1 for i in indices]\n",
    "    \n",
    "    return interest, interest_rank\n",
    "\n",
    "\n",
    "def words_of_interest(input, user=current_user):\n",
    "    # Rank the words in reverse order according to their interest.\n",
    "    indices = local_indices(input, user)\n",
    "    interest, interest_rank = local_interest(input, user)\n",
    "    \n",
    "    words_by_interest = [-1 for i in range(len(indices))]\n",
    "    for i in range(len(indices)):\n",
    "        words_by_interest[-interest_rank[i]] = indices[i]\n",
    "    \n",
    "    return words_by_interest\n",
    "\n",
    "\n",
    "def frequency_weighted_familiarity(input, user=current_user):\n",
    "    indices = local_indices(input, user)\n",
    "    \n",
    "    frequency = [freq[indices[i]] for i in range(len(indices))]\n",
    "    # Each user's associated list is a list of that user's familiarity with each word in the vocabulary.\n",
    "    familiarity, familiarity_rank = local_familiarity(input, user)\n",
    "    \n",
    "    # Here we weight the familiarity by the relative importance of the word to the text.\n",
    "    total_freq = sum(frequency)\n",
    "    fwf = [(frequency[i]/total_freq)*familiarity[i] for i in range(len(indices))]\n",
    "    by_fwf = [ix for fr, ix in sorted(zip(fwf, indices))]\n",
    "    # Rank the words locally by their interest.\n",
    "    fwf_rank = [by_fwf.index(i)+1 for i in indices]\n",
    "    \n",
    "    return fwf, fwf_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_familiar_sentence(word):\n",
    "    if word in vocab:\n",
    "        return sorted(zip([sum(frequency_weighted_familiarity(convert_snippet(phrase))[0]) for phrase in words_to_phrases[word]], words_to_phrases[word]), reverse=True)[0][1]\n",
    "    return \"No example sentence exists.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy focus = 0.25, normal focus = 0.05, sharp focus = 0.005, laser focus = 0.0005.\n",
    "# Easy = 0.75, Medium = 0.5, Hard = 0.25. (Or adjust range between .25 and .75.)\n",
    "# Smoothness ranges between 0 and 1\n",
    "\n",
    "focus_levels = {\"fuzzy\": 0.25, \"normal\": 0.05, \"sharp\": 0.005, \"laser\": 0.0005}\n",
    "difficulty_levels = {\"easy\": 0.75, \"medium\": 0.5, \"hard\": 0.25}\n",
    "\n",
    "current_reps = 20\n",
    "current_focus = \"normal\"\n",
    "current_difficulty = \"medium\"\n",
    "current_smoothness = 0.01\n",
    "        \n",
    "def update_reps(val):\n",
    "    global current_reps\n",
    "    try:\n",
    "        val = int(val)\n",
    "        if val > 0:\n",
    "            current_reps = val\n",
    "        else:\n",
    "            current_reps = 0\n",
    "    except (ValueError, TypeError):\n",
    "        print(\"Reps value must be an integer.\")\n",
    "    return\n",
    "\n",
    "def update_focus(val):\n",
    "    global current_focus\n",
    "    if val in focus_levels.keys():\n",
    "        current_focus = val\n",
    "    else:\n",
    "        print(\"This is not a valid value for focus.\")\n",
    "    return\n",
    "\n",
    "def update_difficulty(val):\n",
    "    global current_difficulty\n",
    "    if val in difficulty_levels.keys():\n",
    "        current_difficulty = val\n",
    "    else:\n",
    "        print(\"This is not a valid value for difficulty.\")\n",
    "    return\n",
    "\n",
    "def update_smoothness(val):\n",
    "    global current_smoothness\n",
    "    try:\n",
    "        val = float(val)\n",
    "        if val > 1:\n",
    "            current_smoothness = 1\n",
    "        elif val < 0:\n",
    "            current_smoothness = 0\n",
    "        else:\n",
    "            current_smoothness = val\n",
    "    except (ValueError, TypeError):\n",
    "        print(\"Smoothness value must be a probability between 0 and 1 inclusive.\")\n",
    "    return\n",
    "\n",
    "def list_parms():\n",
    "    print(\"+---------------------+\")\n",
    "    print(\"| TRAINING PARAMETERS |\")\n",
    "    print(\"+---------------------+\")\n",
    "    print(\"  Reps: \"+str(current_reps))\n",
    "    print(\"  Focus: \"+current_focus)\n",
    "    print(\"  Difficulty: \"+current_difficulty)\n",
    "    print(\"  Smoothness: \"+str(current_smoothness))\n",
    "    print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface\n",
    "In the following cells we create the simple terminal interface to run exercises based on both snippets of Portuguese text extracted from the internet and our existing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzzy focus = 0.25, normal focus = 0.05, sharp focus = 0.005, laser focus = 0.0005.\n",
    "# Easy = 0.75, Medium = 0.5, Hard = 0.25. (Or adjust range between .25 and .75.)\n",
    "# Smoothness ranges between 0 and 1\n",
    "\n",
    "# googletrans package was unreliable...\n",
    "# Used list of sentences instead...\n",
    "def single_exercise(exercise_words=range(len(vocab)), avoid_list=[], user=current_user, mean=difficulty_levels[current_difficulty], focus_width=focus_levels[current_focus], flatness=current_smoothness):\n",
    "    words = []\n",
    "    distr = get_distribution(users[user], m=mean, inv_v=focus_width, flatness=flatness)\n",
    "\n",
    "    words.append(random.choices([i for i in exercise_words if i not in avoid_list and i not in named_entity_indices],\n",
    "                   [distr[i] for i in exercise_words if i not in avoid_list and i not in named_entity_indices])[0])\n",
    "\n",
    "    for i in range(3):\n",
    "        words.append(random.choice([i for i in range(len(vocab)) if i not in words and i not in named_entity_indices]))\n",
    "\n",
    "    indices = list(range(4))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    options = [char for char in'ABCD']\n",
    "    phrases = []\n",
    "    output = [vocab[words[i]] for i in indices]\n",
    "    english_output = []\n",
    "\n",
    "    for i in range(4):\n",
    "        phrases.append(random.choice(words_to_phrases[output[i]]))\n",
    "        english_output.append(pt2en_phrases[phrases[i]])\n",
    "\n",
    "    print('Select the English sentence most likely to contain this word in Portuguese:\\n\\n\"' + vocab[words[0]] +\n",
    "          '\" (Your familiarity with this word is {}%.)\\n'.format(round(100*users[user][words[0]])))\n",
    "    print('Example sentence: ' + most_familiar_sentence(vocab[words[0]]) + \"\\n\")\n",
    "    for i in range(4):\n",
    "        print(options[i] + \") \" + english_output[i])\n",
    "    print(\"\")\n",
    "    print(\"Return on empty to quit.\")\n",
    "    print(\"\")\n",
    "    answer = input()\n",
    "    if answer == \"\":\n",
    "        return None\n",
    "    while answer not in options:\n",
    "        print('\\nPlease enter \"A\", \"B\", \"C\", or \"D\".\\n')\n",
    "        answer = input()\n",
    "    \n",
    "    correct = indices[options.index(answer)] == 0\n",
    "    if correct:\n",
    "        print(\"\\nNice job, {}!\".format(user)+\n",
    "              \"\\nThe original phrase was: '{}'\\n\".format(phrases[indices.index(0)]))\n",
    "    else:\n",
    "        print(\"\\nSorry, {}. The correct answer was {}.\".format(user, options[indices.index(0)])+\n",
    "              \"\\nThe original phrase was: '{}'\".format(phrases[indices.index(0)])+\n",
    "              \"\\nBetter luck next time!\\n\")\n",
    "    update(users[user], words[0], correct)\n",
    "    \n",
    "    return words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(exercise_words=range(len(vocab)), reps=current_reps, user=current_user, mean=difficulty_levels[current_difficulty], focus_width=focus_levels[current_focus], flatness=current_smoothness):        \n",
    "    print(\"\\nHello, {}!\\n\".format(user))\n",
    "    count = 0\n",
    "    avoid_list = []\n",
    "    for i in range(reps):\n",
    "        print(\"-----------\")\n",
    "        print(\"Problem #{}\".format(i+1))\n",
    "        print(\"-----------\")\n",
    "        avoid = single_exercise(exercise_words=exercise_words, avoid_list=avoid_list, user=user, mean=mean, focus_width=focus_width, flatness=flatness)\n",
    "        if avoid:\n",
    "            avoid_list.append(avoid)\n",
    "        else:\n",
    "            break\n",
    "        count+=1\n",
    "    if count > 1:\n",
    "        print(\"\\n{} Exercises Complete!\".format(count))\n",
    "    if count == 1:\n",
    "        print(\"1 Exercise Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_snippet(snippet_name):\n",
    "    if snippet_name in snippets.keys():\n",
    "        ex_words = words_of_interest(snippets[snippet_name])\n",
    "        ex_words = ex_words[:min(current_reps,len(ex_words))]\n",
    "        train(exercise_words=ex_words, reps=len(ex_words))\n",
    "        return\n",
    "    else:\n",
    "        print('This snippet does not exist.')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "\n",
    "error_statement = 'ERROR: Invalid command. Type \\'lc\\' to list valid commands.'\n",
    "    \n",
    "def interpreter():\n",
    "    print(\"Welcome to your Portuguese training, {}!\\n\".format(current_user))\n",
    "    print(\"Type 'lc' for a list of commands.\")\n",
    "    \n",
    "    while True:\n",
    "        command = input()\n",
    "        command = shlex.split(command)\n",
    "        \n",
    "        if len(command) == 0:\n",
    "            print(error_statement)\n",
    "            \n",
    "        # List commands\n",
    "        elif command[0] == 'lc':\n",
    "            print(open('list_commands.txt', encoding='UTF-8').read())\n",
    "            \n",
    "        # Train\n",
    "        elif command[0] == 'train':\n",
    "            # Train on existing knowledge\n",
    "            if len(command) == 1:\n",
    "                train()\n",
    "            # Train on existing snippet\n",
    "            elif len(command) == 2:\n",
    "                train_snippet(command[1])\n",
    "            else:\n",
    "                print(error_statement)\n",
    "                \n",
    "        # Manage snippets\n",
    "        elif command[0] == 'snpts':\n",
    "            # List existing snippets\n",
    "            if len(command) == 1:\n",
    "                list_snippets()\n",
    "            # Print snippet in count format\n",
    "            elif command[1] == '-p':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    print_snippet(command[2])\n",
    "            # Print snippet in original text format\n",
    "            elif command[1] == '-po':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    print_original_snippet(command[2])\n",
    "            # Add a new snippet\n",
    "            elif command[1] == '-a':\n",
    "                if len(command) != 4:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    if re.compile(r'.*\\.txt').fullmatch(command[2]) != None:\n",
    "                        add_snippet(extract_file(command[2]), command[3])\n",
    "                    else:\n",
    "                        add_snippet(command[2], command[3])\n",
    "            # Delete an existing snippet\n",
    "            elif command[1] == '-d':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    delete_snippet(command[2])\n",
    "            else:\n",
    "                print(error_statement)\n",
    "                    \n",
    "        # Manage users\n",
    "        elif command[0] == 'user':\n",
    "            # Print current user\n",
    "            if len(command) == 1:\n",
    "                print(current_user)\n",
    "            # List existing users\n",
    "            elif command[1] == '-l':\n",
    "                if len(command) != 2:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    list_users()\n",
    "            # Change current user\n",
    "            elif command[1] == '-c':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    change_user(command[2])\n",
    "            # Add new user\n",
    "            elif command[1] == '-a':\n",
    "                if len(command) == 3:\n",
    "                    add_user(command[2])\n",
    "                elif len(command) == 4:\n",
    "                    add_user(command[2], level=command[3])\n",
    "                else:\n",
    "                    print(error_statement)                   \n",
    "            # Delete existing user\n",
    "            elif command[1] == '-d':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    delete_user(command[2])\n",
    "            else:\n",
    "                print(error_statement)\n",
    "                    \n",
    "        # Manage parameters\n",
    "        elif command[0] == 'parm':\n",
    "            # List training parameters\n",
    "            if len(command) == 1:\n",
    "                list_parms()\n",
    "            # Update reps\n",
    "            elif command[1] == '-r':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    update_reps(command[2])          \n",
    "            # Update focus\n",
    "            elif command[1] == '-f':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    update_focus(command[2])          \n",
    "            # Update difficulty\n",
    "            elif command[1] == '-d':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    update_difficulty(command[2])          \n",
    "            # Update smoothness\n",
    "            elif command[1] == '-s':\n",
    "                if len(command) != 3:\n",
    "                    print(error_statement)\n",
    "                else:\n",
    "                    update_smoothness(command[2])\n",
    "            else:\n",
    "                print(error_statement)\n",
    "        # Quit\n",
    "        elif command[0] == 'quit':\n",
    "            break\n",
    "        else:\n",
    "            print(error_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Program\n",
    "Finally we run the program and do our language training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to your Portuguese training, Default!\n",
      "\n",
      "Type 'lc' for a list of commands.\n",
      "train\n",
      "\n",
      "Hello, Default!\n",
      "\n",
      "-----------\n",
      "Problem #1\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"nadadores\" (Your familiarity with this word is 1%.)\n",
      "\n",
      "Example sentence: Tom está competindo contra outros nadadores.\n",
      "\n",
      "A) Dolphins are good swimmers.\n",
      "B) Can I ask a dumb question?\n",
      "C) Do it just like this.\n",
      "D) I thought you loved reading.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "B\n",
      "\n",
      "Sorry, Default. The correct answer was A.\n",
      "The original phrase was: 'Golfinhos são bons nadadores.'\n",
      "Better luck next time!\n",
      "\n",
      "-----------\n",
      "Problem #2\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"hilário\" (Your familiarity with this word is 2%.)\n",
      "\n",
      "Example sentence: Você é hilário.\n",
      "\n",
      "A) I'll take any job you can offer me.\n",
      "B) I can't approve of your going out with him.\n",
      "C) You are hilarious.\n",
      "D) Why didn't you ever tell me?\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "C\n",
      "\n",
      "Nice job, Default!\n",
      "The original phrase was: 'Você é hilário.'\n",
      "\n",
      "-----------\n",
      "Problem #3\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"avião\" (Your familiarity with this word is 44%.)\n",
      "\n",
      "Example sentence: O avião em que Tom estava foi atingido por um raio.\n",
      "\n",
      "A) Are you illiterate?\n",
      "B) Never say the word \"bomb\" on an airplane.\n",
      "C) We played golf in spite of the rain.\n",
      "D) Tom didn't know where Mary wanted to spend her summer vacation.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "\n",
      "\n",
      "2 Exercises Complete!\n",
      "lc\n",
      "+--------------+\n",
      "| COMMAND LIST |\n",
      "+--------------+\n",
      "\n",
      "MANAGE COMMANDS\n",
      "    lc ---------------------------> list commands\n",
      "\n",
      "MANAGE TRAINING\n",
      "    train ------------------------> train on existing knowledge\n",
      "    train [snippet name] ---------> train on existing snippet\n",
      "    \n",
      "MANAGE SNIPPETS\n",
      "    snpts ------------------------> list existing snippets\n",
      "    snpts -p [name] --------------> print snippet [name] in wordcount format\n",
      "    snpts -po [name] -------------> print snippet [name] original text\n",
      "    snpts -d [name] --------------> delete existing snippet    \n",
      "    snpts -a [text] [name] -------> import string [text]; save snippet [name]\n",
      "    snpts -a [.txt file] [name] --> import file [.txt file]; save snippet [name]\n",
      "    \n",
      "MANAGE USERS\n",
      "    user -------------------------> print current user\n",
      "    user -l ----------------------> list existing users\n",
      "    user -c [name] ---------------> change current user to [name]\n",
      "    user -a [name] ---------------> add user [name]\n",
      "    user -a [name] [level] -------> add user [name] [level]\n",
      "        levels: [beginner, functional, conversational, advanced, fluent]\n",
      "    user -d [name] ---------------> delete user [name]\n",
      " \n",
      "MANAGE PARAMETERS\n",
      "    parm -------------------------> list current training parameters\n",
      "    parm -r [newval] -------------> update reps paramater to [newval]\n",
      "        reps: [integer greater than 0]\n",
      "    parm -f [newval] -------------> update focus paramater to [newval]\n",
      "        focus: [fuzzy, normal, sharp, laser]\n",
      "    parm -d [newval] -------------> update difficulty paramater to [newval]\n",
      "        difficulty: [easy, medium, hard]\n",
      "    parm -s [newval] -------------> update smoothness paramater to [newval]\n",
      "        smoothness: [probability between 0 and 1 inclusive]\n",
      "\n",
      "QUIT\n",
      "    quit -------------------------> quit program\n",
      "\n",
      "parm\n",
      "+---------------------+\n",
      "| TRAINING PARAMETERS |\n",
      "+---------------------+\n",
      "  Reps: 20\n",
      "  Focus: normal\n",
      "  Difficulty: medium\n",
      "  Smoothness: 0.01\n",
      "\n",
      "snpts\n",
      "+--------------+\n",
      "| SNIPPET LIST |\n",
      "+--------------+\n",
      "  harry_test\n",
      "  harry_test1\n",
      "  harry_test2\n",
      "  harry_test3\n",
      "  harry_test4\n",
      "  harry_test5\n",
      "  harry_test6\n",
      "  harry_test7\n",
      "  snippet8\n",
      "  DDN_0622\n",
      "  blah\n",
      "  English sentence\n",
      "  Genghis Khan\n",
      "  Genghis Wiki Ascension\n",
      "\n",
      "train harry_test\n",
      "\n",
      "Hello, Default!\n",
      "\n",
      "-----------\n",
      "Problem #1\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"casasse\" (Your familiarity with this word is 1%.)\n",
      "\n",
      "Example sentence: Pensei que quisesse que o Tom se casasse com você.\n",
      "\n",
      "A) Tom is helping.\n",
      "B) Do you like this backpack?\n",
      "C) He asked her to marry him, but she refused.\n",
      "D) Your suggestion is of no practical use.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "C\n",
      "\n",
      "Nice job, Default!\n",
      "The original phrase was: 'Ele lhe pediu que se casasse com ele, mas ela recusou.'\n",
      "\n",
      "-----------\n",
      "Problem #2\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"reagiria\" (Your familiarity with this word is 1%.)\n",
      "\n",
      "Example sentence: Como você reagiria?\n",
      "\n",
      "A) It may take many years.\n",
      "B) My toe began to bleed.\n",
      "C) We had less snow this winter than we had expected.\n",
      "D) How would you react?\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "D\n",
      "\n",
      "Nice job, Default!\n",
      "The original phrase was: 'Como você reagiria?'\n",
      "\n",
      "-----------\n",
      "Problem #3\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"trapaceava\" (Your familiarity with this word is 0%.)\n",
      "\n",
      "Example sentence: O Tom sabe que ele trapaceava,\n",
      "\n",
      "A) I was thirteen years old at that time.\n",
      "B) Tom knows he cheated.\n",
      "C) Drinking alcohol during pregnancy can cause birth defects.\n",
      "D) There are many different strategies we could try.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "D\n",
      "\n",
      "Sorry, Default. The correct answer was B.\n",
      "The original phrase was: 'O Tom sabe que ele trapaceava,'\n",
      "Better luck next time!\n",
      "\n",
      "-----------\n",
      "Problem #4\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"matará\" (Your familiarity with this word is 0%.)\n",
      "\n",
      "Example sentence: O chefe me matará.\n",
      "\n",
      "A) He abused my confidence.\n",
      "B) It's remarkable.\n",
      "C) The chief's gonna kill me.\n",
      "D) I tried to cheer him up.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "C\n",
      "\n",
      "Nice job, Default!\n",
      "The original phrase was: 'O chefe me matará.'\n",
      "\n",
      "-----------\n",
      "Problem #5\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"catolicismo\" (Your familiarity with this word is 1%.)\n",
      "\n",
      "Example sentence: Ele é um convertido recente ao catolicismo.\n",
      "\n",
      "A) I would like to brush up my English.\n",
      "B) They shared the money.\n",
      "C) He is a recent convert to Catholicism.\n",
      "D) Did Tom know that you were hungry?\n",
      "\n",
      "Return on empty to quit.\n",
      "\n",
      "C\n",
      "\n",
      "Nice job, Default!\n",
      "The original phrase was: 'Ele é um convertido recente ao catolicismo.'\n",
      "\n",
      "-----------\n",
      "Problem #6\n",
      "-----------\n",
      "Select the English sentence most likely to contain this word in Portuguese:\n",
      "\n",
      "\"acusação\" (Your familiarity with this word is 2%.)\n",
      "\n",
      "Example sentence: Sua acusação é risível.\n",
      "\n",
      "A) Your accusation is preposterous.\n",
      "B) Tom is the dumbest kid in the class.\n",
      "C) We can't sell that bracelet.\n",
      "D) We're models.\n",
      "\n",
      "Return on empty to quit.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-77bdc233c770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-9066407f8fa9>\u001b[0m in \u001b[0;36minterpreter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Train on existing snippet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mtrain_snippet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-00d753dc9f99>\u001b[0m in \u001b[0;36mtrain_snippet\u001b[0;34m(snippet_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnippets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnippet_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mex_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_reps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mex_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-d69dbebb5473>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(exercise_words, reps, user, mean, focus_width, flatness)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Problem #{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mavoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_exercise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexercise_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexercise_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavoid_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavoid_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfocus_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfocus_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mavoid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mavoid_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-5d772d2c345d>\u001b[0m in \u001b[0;36msingle_exercise\u001b[0;34m(exercise_words, avoid_list, user, mean, focus_width, flatness)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Return on empty to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHubProjects/Portuguese-Vocabulary-Exercises/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             )\n\u001b[0;32m--> 857\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHubProjects/Portuguese-Vocabulary-Exercises/venv/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "interpreter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PortugueseVocabularyExercises",
   "language": "python",
   "name": "portuguesevocabularyexercises"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
